{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\nimport arviz as az\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nimport pymc3 as pm\nimport theano\nfrom pymc3.ode import DifferentialEquation\nfrom scipy.integrate import odeint\nplt.style.use(\"seaborn-darkgrid\")\nrng = np.random.default_rng(42)\n\nnoise = 0.3  # amount of noise to inject into ode-solved values\ntune = 1000  # number of tuning steps before we start keeping good data\ncores = 4    # kaggle kernels have 4 cores, so we can use each one to run chains in parallel\neps = 0.5    # we want prior distributions centered near, but not right at, the true value.  eps pushes the prior away from true\n\n# p.129\ntheta = {'beta' : 0.00237, 'alpha': 0.465}\n\n# p.126\ndef SIR(y, t, p):\n    ds = -p[0] * y[0] * y[1]\n    di = p[0] * y[0] * y[1] - p[1] * y[1]\n    return [ds, di]\ntimes = np.arange(1, 15)\ny0 = [760, 3]\n\n# Run ODE\ny = odeint(SIR, y0, times, (list(theta.values()),), rtol=1e-8)\n\n# normalize and adjust parameters accordingly\n# alpha does not change, but beta must be multiplied by n\nn = y[0].sum()\ny_n = y.T/n\ntheta_n = theta.copy()\ntheta_n['beta'] *= n\n\ndef bayesiate(start=1):\n    plt.plot(times, y_n[0], 'r')\n    plt.plot(times, y_n[1], 'b')\n\n    z = y_n.copy()\n    # Replace I class with observations in Table 6.1 p.126\n    z[1,2:] = np.array([25,75,227,296,258,236,192,126,71,28,11,7]) / n\n    # Add noise to S class predictions from odeint \n    z[0] = rng.lognormal(mean=np.log(z[0]), sigma=noise)\n\n    # shift to start at specified start time\n    t0 = times[0]\n    t  = times[start:]\n    z  = z[:,start:]\n    \n    plt.plot(t, z[0], 'r.')\n    plt.plot(t, z[1], 'b.')\n    plt.show()\n\n    # guess loc for priors, but inject some error so Bayes doesn't get to start at the correct answer\n    theta_loc = {key: val * rng.uniform(1-eps, 1+eps) for key,val in theta_n.items()}\n\n    # create pymc3 ODE object\n    sir_model = DifferentialEquation(\n        func=SIR,\n        times=t,\n        t0=t0,\n        n_states=len(y0),\n        n_theta=len(theta),\n    )\n\n    with pm.Model() as model:\n        sigma_prior = pm.HalfCauchy(\"sigma\", 1.0, shape=len(y0))\n        theta_prior = [pm.Lognormal(key, pm.math.log(val), 1) for key,val in theta_loc.items()]\n        sir_curves_n = sir_model(y0=y_n.T[0], theta=theta_prior)\n        Z = pm.Lognormal(\"Z\", mu=pm.math.log(sir_curves_n), sigma=sigma_prior, observed=z.T)\n        trace = pm.sample(tune=tune, draws=4*tune, cores=cores, chains=cores, target_accept=0.9)\n        pm.save_trace(trace, '/kaggle/working/disease')\n        data = az.from_pymc3(trace=trace)\n    az.plot_posterior(data, round_to=2, hdi_prob=0.95);\n\n    theta_df = pd.DataFrame({key: trace.get_values(key) for key in theta.keys()})\n    theta_stats = theta_df.describe().T\n    theta_stats['prior_loc'] = theta_loc.values()\n    theta_stats['true'] = theta_n.values()\n    display(theta_stats)\n    \nbayesiate(1)\nbayesiate(2)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.9","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}