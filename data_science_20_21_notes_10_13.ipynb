{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "data-science-20-21-notes-10-13.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNn0pOfYFWEZYRCKXPqKsbt",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Tarleton-Math/data-science-20-21/blob/master/data_science_20_21_notes_10_13.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uaXRZ9JPAGDT"
      },
      "source": [
        "#  Intro to Naive Bayes and Imputation of Missing Data\n",
        "## Class Notes 2020-10-13\n",
        "## Data Science (masters)\n",
        "## Math 5364 & 5366, Fall 20 & Spring 21\n",
        "## Tarleton State University\n",
        "## Dr. Scott Cook"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Smhze6UlAJIG",
        "outputId": "8317e8cc-288b-4644-993e-9ea4b39fe713",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 649
        }
      },
      "source": [
        "! pip install --upgrade numpy\n",
        "! pip install --upgrade pandas"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting numpy\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/63/97/af8a92864a04bfa48f1b5c9b1f8bf2ccb2847f24530026f26dd223de4ca0/numpy-1.19.2-cp36-cp36m-manylinux2010_x86_64.whl (14.5MB)\n",
            "\u001b[K     |████████████████████████████████| 14.5MB 291kB/s \n",
            "\u001b[31mERROR: tensorflow 2.3.0 has requirement numpy<1.19.0,>=1.16.0, but you'll have numpy 1.19.2 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: albumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: numpy\n",
            "  Found existing installation: numpy 1.18.5\n",
            "    Uninstalling numpy-1.18.5:\n",
            "      Successfully uninstalled numpy-1.18.5\n",
            "Successfully installed numpy-1.19.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Collecting pandas\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a2/21/e10d65222d19a2537e3eb0df306686a9eabd08b3c98dd120e43720bf802d/pandas-1.1.3-cp36-cp36m-manylinux1_x86_64.whl (9.5MB)\n",
            "\u001b[K     |████████████████████████████████| 9.5MB 4.2MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas) (2018.9)\n",
            "Requirement already satisfied, skipping upgrade: python-dateutil>=2.7.3 in /usr/local/lib/python3.6/dist-packages (from pandas) (2.8.1)\n",
            "Requirement already satisfied, skipping upgrade: numpy>=1.15.4 in /usr/local/lib/python3.6/dist-packages (from pandas) (1.19.2)\n",
            "Requirement already satisfied, skipping upgrade: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.7.3->pandas) (1.15.0)\n",
            "Installing collected packages: pandas\n",
            "  Found existing installation: pandas 1.1.2\n",
            "    Uninstalling pandas-1.1.2:\n",
            "      Successfully uninstalled pandas-1.1.2\n",
            "Successfully installed pandas-1.1.3\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "pandas"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wNI3cOsU08nm"
      },
      "source": [
        "Today we meet new more performance measures.  We'll use the Wisconsin Breast Cancer dataset.\n",
        "\n",
        "Up to this point, we've evaluated our models using a confusion matrix and the accuracy.  Accuracy counts all errors as equally bad.  However, there are many cases when some errors are worse than others.  If so, we want our cross-validation and model selection/tuning processes to reflect that fact.\n",
        "\n",
        "Consider the two types of errors for the Wisconsin Breast Cancer dataset\n",
        "1. Classified as benign when actually malignant\n",
        "2. Classified as malignant when actually benign\n",
        "\n",
        "Type I errors are WAY worse.  The patient is unaware that they have cancer and, hence, do not seek treatment.  Type II is certainly undesirable and may lead to unnecessary medical treatment that carry their own risks.  Still, this is far better than leaving a cancer untreated.\n",
        "\n",
        "This oberservation gave rise to a BUNCH of terms over the years.  [Here](https://en.wikipedia.org/wiki/Sensitivity_and_specificity) is a nice summary.  [Here](https://scikit-learn.org/stable/modules/model_evaluation.html#) is the scikit learn module implementing there.\n",
        "\n",
        "## Numeric scores\n",
        "\n",
        "|   \t |     \t   |   \t     |\n",
        "|:------:|:-------:|:-------:|\n",
        "|Actual 0|true negative (TN)|false positive (FP)|\n",
        "|Actual 1|false negative (FN)|true positive (TP)|\n",
        "|   \t |Predict 0|Predict 1|\n",
        "\n",
        "\n",
        "Divide by *ROW* sums\n",
        "\n",
        "|   \t |     \t   |   \t     |\n",
        "|:------:|:-------:|:-------:|\n",
        "|Actual 0|specificity / selectivity / true negative rate (TNR)|fall out / false positive rate (FPR)|\n",
        "|Actual 1|miss rate / false negative rate (FNR)|sensitivity / recall / hit rate / true positive rate (TPR)|\n",
        "|   \t |Predict 0|Predict 1|\n",
        "\n",
        "Divide by *COLUMN* sums\n",
        "\n",
        "|   \t |     \t   |   \t     |\n",
        "|:------:|:-------:|:-------:|\n",
        "|Actual 0|negative predictive value (NPV)|false discovery rate (FDR)|\n",
        "|Actual 1|false omission rate (FOR)|precision/positive predictive value (PPV)|\n",
        "|   \t |Predict 0|Predict 1|\n",
        "\n",
        "\n",
        "- def: accuracy = $\\frac{TP+TN}{TP+TN+FP+FN}$\n",
        "- def: balanced accuracy = $\\frac{TPR+TNR}{2}$\n",
        "- def: $F_1=2*\\frac{PPV \\cdot TPR}{PPV + TPR}$ ([harmonic mean](https://en.wikipedia.org/wiki/Harmonic_mean) of precision and recall)\n",
        "- def: $F_{\\beta}=(1+\\beta^2)*\\frac{PPV \\cdot TPR}{\\beta^2 PPV + TPR}$ (makes TPR (recall) approximately $\\beta$ times more important than precision\n",
        "    - $\\beta \\to 0$, $F_{\\beta} \\to PPV$\n",
        "    - $\\beta \\to \\infty$, $F_{\\beta} \\to TPR$\n",
        "There are more like this.\n",
        "\n",
        "## Curves\n",
        "- Precision-Recall Curve\n",
        "- Receiver-Operator Curve\n",
        "\n",
        "Classfiers produce the predict_proba vector giving the predicted probability that an observation belong to each class. We are NOT forced to simply take the largest one as the prediction.  We can select a threshhold $p^*$ so that classify predicts class 1 iff the probabiity exceed $p^*$.  We then vary $p^*$ and compute the precision, recall, specificity, etc and plot them as a parametrized curve.\n",
        "\n",
        "\n",
        "\n"
      ]
    }
  ]
}