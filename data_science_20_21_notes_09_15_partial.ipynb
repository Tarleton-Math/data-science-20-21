{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "data-science-20-21-notes-09-15_partial.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Tarleton-Math/data-science-20-21/blob/master/data_science_20_21_notes_09_15_partial.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZNlpEYHNjcT_",
        "colab_type": "text"
      },
      "source": [
        "#  Intro to Supervised Learning\n",
        "## One-Hot Encoding, Cross-Validation, and k-Nearest Neighbors\n",
        "## Class Notes 2020-09-15\n",
        "## Data Science (masters)\n",
        "## Math 5364 & 5366, Fall 20 & Spring 21\n",
        "## Tarleton State University\n",
        "## Dr. Scott Cook"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZsUdDDkFjf47",
        "colab_type": "text"
      },
      "source": [
        "# Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lwvZzDxKyb9g",
        "colab_type": "text"
      },
      "source": [
        "We need to update Numpy and Pandas to take advantage of [Numpy's recently improved random number generatation](https://numpy.org/devdocs/reference/random/index.html).  Click \"Restart Runtime\" when complete."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l1-iLinGyNCP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 126
        },
        "outputId": "bdb228d2-0839-4a77-8cb1-e36633c8dc78"
      },
      "source": [
        "! pip install --upgrade numpy\n",
        "! pip install --upgrade pandas"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already up-to-date: numpy in /usr/local/lib/python3.6/dist-packages (1.19.2)\n",
            "Requirement already up-to-date: pandas in /usr/local/lib/python3.6/dist-packages (1.1.2)\n",
            "Requirement already satisfied, skipping upgrade: python-dateutil>=2.7.3 in /usr/local/lib/python3.6/dist-packages (from pandas) (2.8.1)\n",
            "Requirement already satisfied, skipping upgrade: numpy>=1.15.4 in /usr/local/lib/python3.6/dist-packages (from pandas) (1.19.2)\n",
            "Requirement already satisfied, skipping upgrade: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas) (2018.9)\n",
            "Requirement already satisfied, skipping upgrade: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.7.3->pandas) (1.15.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3VQ_3hn54ua_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "ad5d3d95-10ed-411c-c036-ec880bffef2f"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.datasets import load_wine\n",
        "data = load_wine()\n",
        "n, p = data.data.shape\n",
        "print(data.DESCR)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            ".. _wine_dataset:\n",
            "\n",
            "Wine recognition dataset\n",
            "------------------------\n",
            "\n",
            "**Data Set Characteristics:**\n",
            "\n",
            "    :Number of Instances: 178 (50 in each of three classes)\n",
            "    :Number of Attributes: 13 numeric, predictive attributes and the class\n",
            "    :Attribute Information:\n",
            " \t\t- Alcohol\n",
            " \t\t- Malic acid\n",
            " \t\t- Ash\n",
            "\t\t- Alcalinity of ash  \n",
            " \t\t- Magnesium\n",
            "\t\t- Total phenols\n",
            " \t\t- Flavanoids\n",
            " \t\t- Nonflavanoid phenols\n",
            " \t\t- Proanthocyanins\n",
            "\t\t- Color intensity\n",
            " \t\t- Hue\n",
            " \t\t- OD280/OD315 of diluted wines\n",
            " \t\t- Proline\n",
            "\n",
            "    - class:\n",
            "            - class_0\n",
            "            - class_1\n",
            "            - class_2\n",
            "\t\t\n",
            "    :Summary Statistics:\n",
            "    \n",
            "    ============================= ==== ===== ======= =====\n",
            "                                   Min   Max   Mean     SD\n",
            "    ============================= ==== ===== ======= =====\n",
            "    Alcohol:                      11.0  14.8    13.0   0.8\n",
            "    Malic Acid:                   0.74  5.80    2.34  1.12\n",
            "    Ash:                          1.36  3.23    2.36  0.27\n",
            "    Alcalinity of Ash:            10.6  30.0    19.5   3.3\n",
            "    Magnesium:                    70.0 162.0    99.7  14.3\n",
            "    Total Phenols:                0.98  3.88    2.29  0.63\n",
            "    Flavanoids:                   0.34  5.08    2.03  1.00\n",
            "    Nonflavanoid Phenols:         0.13  0.66    0.36  0.12\n",
            "    Proanthocyanins:              0.41  3.58    1.59  0.57\n",
            "    Colour Intensity:              1.3  13.0     5.1   2.3\n",
            "    Hue:                          0.48  1.71    0.96  0.23\n",
            "    OD280/OD315 of diluted wines: 1.27  4.00    2.61  0.71\n",
            "    Proline:                       278  1680     746   315\n",
            "    ============================= ==== ===== ======= =====\n",
            "\n",
            "    :Missing Attribute Values: None\n",
            "    :Class Distribution: class_0 (59), class_1 (71), class_2 (48)\n",
            "    :Creator: R.A. Fisher\n",
            "    :Donor: Michael Marshall (MARSHALL%PLU@io.arc.nasa.gov)\n",
            "    :Date: July, 1988\n",
            "\n",
            "This is a copy of UCI ML Wine recognition datasets.\n",
            "https://archive.ics.uci.edu/ml/machine-learning-databases/wine/wine.data\n",
            "\n",
            "The data is the results of a chemical analysis of wines grown in the same\n",
            "region in Italy by three different cultivators. There are thirteen different\n",
            "measurements taken for different constituents found in the three types of\n",
            "wine.\n",
            "\n",
            "Original Owners: \n",
            "\n",
            "Forina, M. et al, PARVUS - \n",
            "An Extendible Package for Data Exploration, Classification and Correlation. \n",
            "Institute of Pharmaceutical and Food Analysis and Technologies,\n",
            "Via Brigata Salerno, 16147 Genoa, Italy.\n",
            "\n",
            "Citation:\n",
            "\n",
            "Lichman, M. (2013). UCI Machine Learning Repository\n",
            "[https://archive.ics.uci.edu/ml]. Irvine, CA: University of California,\n",
            "School of Information and Computer Science. \n",
            "\n",
            ".. topic:: References\n",
            "\n",
            "  (1) S. Aeberhard, D. Coomans and O. de Vel, \n",
            "  Comparison of Classifiers in High Dimensional Settings, \n",
            "  Tech. Rep. no. 92-02, (1992), Dept. of Computer Science and Dept. of  \n",
            "  Mathematics and Statistics, James Cook University of North Queensland. \n",
            "  (Also submitted to Technometrics). \n",
            "\n",
            "  The data was used with many others for comparing various \n",
            "  classifiers. The classes are separable, though only RDA \n",
            "  has achieved 100% correct classification. \n",
            "  (RDA : 100%, QDA 99.4%, LDA 98.9%, 1NN 96.1% (z-transformed data)) \n",
            "  (All results using the leave-one-out technique) \n",
            "\n",
            "  (2) S. Aeberhard, D. Coomans and O. de Vel, \n",
            "  \"THE CLASSIFICATION PERFORMANCE OF RDA\" \n",
            "  Tech. Rep. no. 92-01, (1992), Dept. of Computer Science and Dept. of \n",
            "  Mathematics and Statistics, James Cook University of North Queensland. \n",
            "  (Also submitted to Journal of Chemometrics).\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "to_qEukh4w6b",
        "colab_type": "text"
      },
      "source": [
        "First, we shuffle the rows.  Often, datasets come sorted.  This means the top n rows are probably statistically different from the bottom n rows.  When we split the dataset, this can accidentally introduce bias.  To prevent this, we shuffle the dataset immediately."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u63n6UiwzVP4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 607
        },
        "outputId": "ac29eb54-4a6e-4df6-cd85-03f0ea1b9617"
      },
      "source": [
        "# fill in - watch video from 9/15"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>alcohol</th>\n",
              "      <th>malic_acid</th>\n",
              "      <th>ash</th>\n",
              "      <th>alcalinity_of_ash</th>\n",
              "      <th>magnesium</th>\n",
              "      <th>total_phenols</th>\n",
              "      <th>flavanoids</th>\n",
              "      <th>nonflavanoid_phenols</th>\n",
              "      <th>proanthocyanins</th>\n",
              "      <th>color_intensity</th>\n",
              "      <th>hue</th>\n",
              "      <th>od280/od315_of_diluted_wines</th>\n",
              "      <th>proline</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>12.36</td>\n",
              "      <td>3.83</td>\n",
              "      <td>2.38</td>\n",
              "      <td>21.0</td>\n",
              "      <td>88.0</td>\n",
              "      <td>2.30</td>\n",
              "      <td>0.92</td>\n",
              "      <td>0.50</td>\n",
              "      <td>1.04</td>\n",
              "      <td>7.65</td>\n",
              "      <td>0.56</td>\n",
              "      <td>1.58</td>\n",
              "      <td>520.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>11.45</td>\n",
              "      <td>2.40</td>\n",
              "      <td>2.42</td>\n",
              "      <td>20.0</td>\n",
              "      <td>96.0</td>\n",
              "      <td>2.90</td>\n",
              "      <td>2.79</td>\n",
              "      <td>0.32</td>\n",
              "      <td>1.83</td>\n",
              "      <td>3.25</td>\n",
              "      <td>0.80</td>\n",
              "      <td>3.39</td>\n",
              "      <td>625.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>14.06</td>\n",
              "      <td>2.15</td>\n",
              "      <td>2.61</td>\n",
              "      <td>17.6</td>\n",
              "      <td>121.0</td>\n",
              "      <td>2.60</td>\n",
              "      <td>2.51</td>\n",
              "      <td>0.31</td>\n",
              "      <td>1.25</td>\n",
              "      <td>5.05</td>\n",
              "      <td>1.06</td>\n",
              "      <td>3.58</td>\n",
              "      <td>1295.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>12.60</td>\n",
              "      <td>2.46</td>\n",
              "      <td>2.20</td>\n",
              "      <td>18.5</td>\n",
              "      <td>94.0</td>\n",
              "      <td>1.62</td>\n",
              "      <td>0.66</td>\n",
              "      <td>0.63</td>\n",
              "      <td>0.94</td>\n",
              "      <td>7.10</td>\n",
              "      <td>0.73</td>\n",
              "      <td>1.58</td>\n",
              "      <td>695.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>13.05</td>\n",
              "      <td>1.73</td>\n",
              "      <td>2.04</td>\n",
              "      <td>12.4</td>\n",
              "      <td>92.0</td>\n",
              "      <td>2.72</td>\n",
              "      <td>3.27</td>\n",
              "      <td>0.17</td>\n",
              "      <td>2.91</td>\n",
              "      <td>7.20</td>\n",
              "      <td>1.12</td>\n",
              "      <td>2.91</td>\n",
              "      <td>1150.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>173</th>\n",
              "      <td>14.38</td>\n",
              "      <td>1.87</td>\n",
              "      <td>2.38</td>\n",
              "      <td>12.0</td>\n",
              "      <td>102.0</td>\n",
              "      <td>3.30</td>\n",
              "      <td>3.64</td>\n",
              "      <td>0.29</td>\n",
              "      <td>2.96</td>\n",
              "      <td>7.50</td>\n",
              "      <td>1.20</td>\n",
              "      <td>3.00</td>\n",
              "      <td>1547.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>174</th>\n",
              "      <td>13.36</td>\n",
              "      <td>2.56</td>\n",
              "      <td>2.35</td>\n",
              "      <td>20.0</td>\n",
              "      <td>89.0</td>\n",
              "      <td>1.40</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.37</td>\n",
              "      <td>0.64</td>\n",
              "      <td>5.60</td>\n",
              "      <td>0.70</td>\n",
              "      <td>2.47</td>\n",
              "      <td>780.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>175</th>\n",
              "      <td>13.28</td>\n",
              "      <td>1.64</td>\n",
              "      <td>2.84</td>\n",
              "      <td>15.5</td>\n",
              "      <td>110.0</td>\n",
              "      <td>2.60</td>\n",
              "      <td>2.68</td>\n",
              "      <td>0.34</td>\n",
              "      <td>1.36</td>\n",
              "      <td>4.60</td>\n",
              "      <td>1.09</td>\n",
              "      <td>2.78</td>\n",
              "      <td>880.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>176</th>\n",
              "      <td>12.29</td>\n",
              "      <td>1.41</td>\n",
              "      <td>1.98</td>\n",
              "      <td>16.0</td>\n",
              "      <td>85.0</td>\n",
              "      <td>2.55</td>\n",
              "      <td>2.50</td>\n",
              "      <td>0.29</td>\n",
              "      <td>1.77</td>\n",
              "      <td>2.90</td>\n",
              "      <td>1.23</td>\n",
              "      <td>2.74</td>\n",
              "      <td>428.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>177</th>\n",
              "      <td>12.25</td>\n",
              "      <td>4.72</td>\n",
              "      <td>2.54</td>\n",
              "      <td>21.0</td>\n",
              "      <td>89.0</td>\n",
              "      <td>1.38</td>\n",
              "      <td>0.47</td>\n",
              "      <td>0.53</td>\n",
              "      <td>0.80</td>\n",
              "      <td>3.85</td>\n",
              "      <td>0.75</td>\n",
              "      <td>1.27</td>\n",
              "      <td>720.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>178 rows × 13 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     alcohol  malic_acid   ash  ...   hue  od280/od315_of_diluted_wines  proline\n",
              "0      12.36        3.83  2.38  ...  0.56                          1.58    520.0\n",
              "1      11.45        2.40  2.42  ...  0.80                          3.39    625.0\n",
              "2      14.06        2.15  2.61  ...  1.06                          3.58   1295.0\n",
              "3      12.60        2.46  2.20  ...  0.73                          1.58    695.0\n",
              "4      13.05        1.73  2.04  ...  1.12                          2.91   1150.0\n",
              "..       ...         ...   ...  ...   ...                           ...      ...\n",
              "173    14.38        1.87  2.38  ...  1.20                          3.00   1547.0\n",
              "174    13.36        2.56  2.35  ...  0.70                          2.47    780.0\n",
              "175    13.28        1.64  2.84  ...  1.09                          2.78    880.0\n",
              "176    12.29        1.41  1.98  ...  1.23                          2.74    428.0\n",
              "177    12.25        4.72  2.54  ...  0.75                          1.27    720.0\n",
              "\n",
              "[178 rows x 13 columns]"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "array([2, 1, 0, 2, 0, 0, 2, 1, 0, 2, 1, 0, 0, 0, 0, 2, 0, 0, 0, 0, 1, 0,\n",
              "       1, 1, 1, 2, 1, 2, 0, 1, 2, 2, 1, 0, 1, 1, 2, 1, 1, 2, 2, 2, 2, 0,\n",
              "       0, 0, 1, 0, 1, 1, 0, 2, 1, 1, 0, 2, 2, 2, 0, 1, 1, 0, 1, 1, 1, 1,\n",
              "       1, 1, 2, 2, 0, 2, 1, 0, 2, 0, 2, 1, 1, 1, 2, 2, 1, 2, 1, 1, 0, 1,\n",
              "       0, 1, 1, 1, 1, 2, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 2, 1, 1, 2, 2, 0,\n",
              "       1, 2, 1, 2, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 2, 0, 1, 2, 0,\n",
              "       1, 2, 1, 2, 1, 2, 0, 0, 2, 1, 0, 2, 0, 2, 0, 1, 1, 2, 0, 0, 0, 2,\n",
              "       0, 0, 0, 0, 1, 0, 0, 1, 2, 2, 0, 1, 0, 0, 2, 1, 0, 1, 2, 0, 2, 0,\n",
              "       1, 2])"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ElmBdFcl5_C9",
        "colab_type": "text"
      },
      "source": [
        "We frequently convert a categorical variable $X$ into boolean variables as follows:\n",
        "\n",
        "def: If $X$ is a categorical variable with levels $0,1,\\dots,l$, its *one-hot-encoding/dummy variables/indicator variables* are $l+1$ boolean variables $B_0, B_1, \\dots, B_{l}$ where: $$B_{ij}=1 \\mbox{ if } X_i=j$$ $$B_{ij}=0 \\mbox{ if } X_i\\neq j$$\n",
        "\n",
        "Sklearn has convenience commands such as [OneHotEncoder](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OneHotEncoder.html) and its [friends](https://scikit-learn.org/stable/modules/classes.html#module-sklearn.preprocessing), but let's write it ourselves this time.  Admittedly, sklearn's version has a lot more options.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b78-64Rn86tX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "outputId": "03505d9e-aa7d-4684-e4ef-3e270677be9c"
      },
      "source": [
        "def my_one_hot_encoder(X):\n",
        "    # fill in - watch video from 9/15\n",
        "\n",
        "targ = my_one_hot_encoder(targets)\n",
        "targ_names = targ.columns\n",
        "feat_names = feat.columns\n",
        "targ"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0_ind</th>\n",
              "      <th>1_ind</th>\n",
              "      <th>2_ind</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>173</th>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>174</th>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>175</th>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>176</th>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>177</th>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>178 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     0_ind  1_ind  2_ind\n",
              "0    False  False   True\n",
              "1    False   True  False\n",
              "2     True  False  False\n",
              "3    False  False   True\n",
              "4     True  False  False\n",
              "..     ...    ...    ...\n",
              "173   True  False  False\n",
              "174  False  False   True\n",
              "175   True  False  False\n",
              "176  False   True  False\n",
              "177  False  False   True\n",
              "\n",
              "[178 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p77szobAWVoL",
        "colab_type": "text"
      },
      "source": [
        "# Cross-Validation Methods\n",
        "\n",
        "- $k$-fold - Divide into $k$ equal pieces (as close as possible) called *folds*.  Loop through the folds, using 1 fold for validation and remainder for training.\n",
        "    - Deterministic\n",
        "    - $k$ cv cycles\n",
        "    - Each row used for validation exactly once\n",
        "    - Special Case: Called *leave-one-out* if $k$=$n$; note each fold contains 1 row.\n",
        "- Delete-$d$ - Select $n-d$ rows *WITHOUT* replacement for training and remaining for validation.\n",
        "    - Random\n",
        "    - Arbitrary number of cv cycles\n",
        "        - could loop determininstically through all $n \\choose d$ subsets of size $d$, but that's typically VERY big\n",
        "    - Row used for validation a variable number of times\n",
        "- Bootstrap - Select $n$ rows *WITH* replacement  for training and any rows never selected for validation.\n",
        "    - Random\n",
        "    - Arbitrary number of cv cycles\n",
        "    - A row may be selected multiple times for the training set\n",
        "    - Average size of validation set $= e^{-1}n\\approx 0.368n$ and training set $=(1-e^{-1})n \\approx 0.632n$.\n",
        "        - Why?  To be in validation set, row must never be chosen.\n",
        "        - Prob chosen during any single selection is $\\frac{1}{n}$ and prob not chosen is $1-\\frac{1}{n}$.\n",
        "        - So prob not chosen on any of $n$ selections is $\\left(1-\\frac{1}{n}\\right)^n$.\n",
        "        - Calc 2 (L'Hopitals Rule) $\\displaystyle \\lim_{n \\to \\infty} \\left(1+\\frac{a}{n}\\right)^n = e^a$\n",
        "        - Let $a=-1$ to see prob not selection on any of $n$ selections $\\to e^{-1}$.\n",
        "        - So, expected size of validation set $\\to e^{-1}n$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WjYa6yqsLtqT",
        "colab_type": "text"
      },
      "source": [
        "Now we need to split our holdout set and modeling set.  Again, sklearn offers convenience commands like [train_test_split](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html#sklearn.model_selection.train_test_split) and its [friends](https://scikit-learn.org/stable/modules/classes.html#module-sklearn.model_selection), but we'd like to write our own."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tIqK6Bqh0OWt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def make_split(df, train_idx):\n",
        "    # fill in - watch video from 9/17\n",
        "\n",
        "def k_folds_cv(df, num_folds, which_fold=0):\n",
        "    # fill in - watch video from 9/17\n",
        "    return make_split(df, train_idx)\n",
        "\n",
        "def delete_d_cv(df, d=1):\n",
        "    # fill in - hwk04\n",
        "    return make_split(df, train_idx)\n",
        "\n",
        "def bootstrap_cv(df):\n",
        "    # fill in - hwk04\n",
        "    return make_split(df, train_idx)\n",
        "\n",
        "df = feat\n",
        "df[targ.columns] = targ\n",
        "df['class'] = targets\n",
        "df_holdout, df_model = delete_d_cv(df, int(n/10))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4j0VL5UGjumD",
        "colab_type": "text"
      },
      "source": [
        "# k-Nearest Neighbors"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xuvs-gA3yedz",
        "colab_type": "text"
      },
      "source": [
        "$k$-Nearest Neighbors is our first supervised learning technique.  Though there are variants for other situations, the most basic version applies when the features are continuous and the target(s) catgorical.  Thus, the basic knn is a *classifier*.\n",
        "\n",
        "Basic idea: For each row in the validation set, we predict its target class by finding the $k$ training rows which are closest (\\*) wrt the features.  These get to \"vote\" on the predicted class for that validation row.\n",
        "\n",
        "def: The vector containing the vote proportions for each class is called *predict_proba* (must sum to 1).  The class with the highest vote proportion is the *prediction*.\n",
        "\n",
        "There are many improvements to this basic algorithm, including allowing weights on the votes (usually closer neighbors' votes get more weight).  See [scikit-learn's version](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html).\n",
        "\n",
        "(\\*)\n",
        "def: The *$l^p$* distance between two vectors $\\vec{x}$ and $\\vec{y}$ is $\\displaystyle \\left(\\sum_i |x_i-y_i|^p \\right)^{1/p}$\n",
        "- $p=2$ is the standard Euclidean distance\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VhGfvlW1yQJs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def my_knn(feat_valid, feat_train, targ_train, n_neighbors=4, p=2):\n",
        "    # v, d = feat_valid.shape\n",
        "    # t, d = feat_train.shape\n",
        "    # t, q = targ_train.shape\n",
        "    # p = 2 denotes Euclidean distance\n",
        "\n",
        "    k = n_neighbors-1  # because n_neighbors neighbors will be in slots 0,1,...,n_neighbors-1\n",
        "    DX = # fill in - hwk04  # DX.shape=(v,t,q), DX[a,b,c] = feat_valid[a,c] - feat_train[b,c]\n",
        "    D = # fill in - hwk04  # D.shape=(v,t,1), D[a,b,:] = L^p distance from feat_valid[a] to feat_train[b]\n",
        "    D, targ_train = np.broadcast_arrays(D, targ_train)  # broadcast so D.shape from (v,t,1)→(v,t,q) & targ_train.shape from (t,q)→(v,t,q)\n",
        "    E = np.partition(D, k, axis=1)  # E.shape=(v,t,q); performs partial sort so that E[a,k,:] = distance between feat_valid[a] and its kth closest train neighbor\n",
        "    D_cutoff = E[:,[k],:]  # D_cutoff.shape=(v,1,q); D_cutoff[a,:,:] = distance between feat_valid[a] and its kth closest train neighbor\n",
        "\n",
        "    weight = # fill in - hwk04  # weight.shape=(v,t,q), weight[a,b,:]=1 if D[a,b,:] <= D_cutoff[a] & 0 otherwise\n",
        "    votes = # fill in - hwk04  # vote.shape=(v,t,q), vote[a,b,c]=targ_train[:,b,c]*weight[a,b,:]\n",
        "    votes_sum = # fill in - hwk04  # votes_sum.shape=(v,q), votes_sum[a,c]=sum of votes for valid[a] to be class c\n",
        "    s = # fill in - hwk04  #s.shape=(v,1), s[a,:]=sum of votes for valid[a]\n",
        "    predict_proba = # fill in - hwk04  # predict_proba.shape=(v,q), predict_proba[a,c]=proportion of votes for valid[a] to be class c\n",
        "    predict = # fill in - hwk04  # predict.shape=(v), predict[a]=class with most votes for valid[a]\n",
        "    return predict, predict_proba"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_lDoYqyajodI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        },
        "outputId": "f7f87ea2-f4c3-435f-82ef-b893059ca996"
      },
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier as sk_knn\n",
        "\n",
        "num_folds = 5\n",
        "n_neighbors = 4\n",
        "sk_clf = sk_knn(n_neighbors)\n",
        "for f in range(num_folds):\n",
        "    valid, train = k_folds_cv(df_model, num_folds, f)\n",
        "    X_valid, X_train, Y_train = valid[feat_names].to_numpy(), train[feat_names].to_numpy(), train[targ_names].to_numpy()\n",
        "    \n",
        "    my_predict, my_predict_proba = my_knn(X_valid, X_train, Y_train, n_neighbors)\n",
        "\n",
        "    sk_clf.fit(X_train, train['class'])\n",
        "    sk_predict = sk_clf.predict(X_valid)\n",
        "    sk_predict_proba = sk_clf.predict_proba(X_valid)\n",
        "    residual = ((sk_predict_proba - my_predict_proba)**2).sum()\n",
        "    print(residual)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}